{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "rcParams['lines.linewidth'] = 3\n",
    "rcParams['xtick.labelsize'] = 'x-large'\n",
    "rcParams['ytick.labelsize'] = 'x-large'\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from xgboost import XGBClassifier\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>contact_group</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  balance  housing  loan  duration  campaign  previous  y  \\\n",
       "0   58        0     2143        1     0  4.350000         1         0  0   \n",
       "1   44        0       29        1     0  2.516667         1         0  0   \n",
       "\n",
       "   contact_group  ...  marital_divorced  marital_married  marital_single  \\\n",
       "0              0  ...                 0                1               0   \n",
       "1              0  ...                 0                0               1   \n",
       "\n",
       "   education_primary  education_secondary  education_tertiary  \\\n",
       "0                  0                    0                   1   \n",
       "1                  0                    1                   0   \n",
       "\n",
       "   poutcome_failure  poutcome_other  poutcome_success  poutcome_unknown  \n",
       "0                 0               0                 0                 1  \n",
       "1                 0               0                 0                 1  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_modeling.csv',sep=',')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (45206, 25) and that of y is (45206,)\n"
     ]
    }
   ],
   "source": [
    "y = df['y'].values\n",
    "X = df.drop(labels = ['y'], axis = 1)\n",
    "print(\"Shape of X is {} and that of y is {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (59878, 25) and that of y is (59878,)\n"
     ]
    }
   ],
   "source": [
    "X_sm, y_sm = over_sampling.SMOTE(0.5).fit_resample(X, y)\n",
    "print(\"Shape of X is {} and that of y is {}\".format(X_sm.shape, y_sm.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add constraint for Logistic Regression using statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stat = sm.add_constant(X_train)\n",
    "X_test_stat = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification(model, xtrain, ytrain, xtest, ytest):\n",
    "    ypred = model.predict(xtest)\n",
    "    ypred = (ypred > 0.5).astype(int)\n",
    "    y_train = model.predict(xtrain)\n",
    "    y_train = (y_train > 0.5).astype(int)\n",
    "    \n",
    "    return accuracy_score(ytest, ypred), precision_score(ytest, ypred), recall_score(ytest, ypred), roc_auc_score(ytest, ypred), f1_score(ytest, ypred), f1_score(ytrain, y_train)\n",
    "    \n",
    "def show_feature_importance(model):\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.xlabel('score')\n",
    "    plt.ylabel('feature')\n",
    "    plt.title('feature importance score')\n",
    "\n",
    "def show_best_hyperparameter(model, hyperparameters):\n",
    "    for key, value in hyperparameters.items() :\n",
    "        print('Best '+key+':', model.get_params()[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"KNN\" : KNeighborsClassifier(),\n",
    "    \"AdaBoost\" :AdaBoostClassifier(random_state=42),\n",
    "    \"XGBoost\" : XGBClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\" : RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression Statsmodel\" : sm.Logit(y_train,X_train_stat),\n",
    "    \"Logistic Regression\" : LogisticRegression(random_state=42)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model KNN score:\n",
      "Accuracy (Test Set): 0.85\n",
      "Precision (Test Set): 0.74\n",
      "Recall (Test Set): 0.85\n",
      "AUC (Test Set) : 0.85\n",
      "F1-Score (Test Set): 0.79\n",
      "F1-Score (Train Set): 0.86\n",
      "\n",
      "Model AdaBoost score:\n",
      "Accuracy (Test Set): 0.90\n",
      "Precision (Test Set): 0.89\n",
      "Recall (Test Set): 0.82\n",
      "AUC (Test Set) : 0.88\n",
      "F1-Score (Test Set): 0.85\n",
      "F1-Score (Train Set): 0.85\n",
      "\n",
      "Model XGBoost score:\n",
      "[21:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy (Test Set): 0.92\n",
      "Precision (Test Set): 0.90\n",
      "Recall (Test Set): 0.84\n",
      "AUC (Test Set) : 0.90\n",
      "F1-Score (Test Set): 0.87\n",
      "F1-Score (Train Set): 0.92\n",
      "\n",
      "Model Decision Tree score:\n",
      "Accuracy (Test Set): 0.87\n",
      "Precision (Test Set): 0.80\n",
      "Recall (Test Set): 0.82\n",
      "AUC (Test Set) : 0.86\n",
      "F1-Score (Test Set): 0.81\n",
      "F1-Score (Train Set): 1.00\n",
      "\n",
      "Model Random Forest score:\n",
      "Accuracy (Test Set): 0.92\n",
      "Precision (Test Set): 0.90\n",
      "Recall (Test Set): 0.84\n",
      "AUC (Test Set) : 0.90\n",
      "F1-Score (Test Set): 0.87\n",
      "F1-Score (Train Set): 1.00\n",
      "\n",
      "Model Logistic Regression Statsmodel score:\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.20791486021435127\n",
      "            Iterations: 188\n",
      "            Function evaluations: 199\n",
      "            Gradient evaluations: 188\n",
      "Accuracy (Test Set): 0.91\n",
      "Precision (Test Set): 0.92\n",
      "Recall (Test Set): 0.80\n",
      "AUC (Test Set) : 0.88\n",
      "F1-Score (Test Set): 0.86\n",
      "F1-Score (Train Set): 0.86\n",
      "\n",
      "Model Logistic Regression score:\n",
      "Accuracy (Test Set): 0.87\n",
      "Precision (Test Set): 0.84\n",
      "Recall (Test Set): 0.77\n",
      "AUC (Test Set) : 0.85\n",
      "F1-Score (Test Set): 0.80\n",
      "F1-Score (Train Set): 0.81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for model in models:\n",
    "  print(\"Model \"+model + \" score:\")\n",
    "  classifier = models[model]\n",
    "  if model!=\"Logistic Regression Statsmodel\" :\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = eval_classification(classifier,X_train,y_train,X_test,y_test)\n",
    "  else:\n",
    "    result = classifier.fit_regularized(random_state = 42)\n",
    "    score = eval_classification(result, X_train_stat, y_train, X_test_stat, y_test)\n",
    "\n",
    "  scores.append([model,score[0],score[1], score[2], score[3], score[4], score[5]])\n",
    "\n",
    "  print(\"Accuracy (Test Set): %.2f\" % score[0])\n",
    "  print(\"Precision (Test Set): %.2f\" % score[1])\n",
    "  print(\"Recall (Test Set): %.2f\" % score[2])\n",
    "  print(\"AUC (Test Set) : %.2f\" % score[3])\n",
    "  print(\"F1-Score (Test Set): %.2f\" % score[4])\n",
    "  print(\"F1-Score (Train Set): %.2f\" % score[5])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metric used in this model is F1, because the dataset has an imbalance target and we want to focuses on predicted positive label correctly. Recall is also used as a supporting metric because in this case we are trying to reduce the number of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1(test)</th>\n",
       "      <th>F1(train)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.915832</td>\n",
       "      <td>0.896674</td>\n",
       "      <td>0.844132</td>\n",
       "      <td>0.897839</td>\n",
       "      <td>0.869610</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.915442</td>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.839109</td>\n",
       "      <td>0.896287</td>\n",
       "      <td>0.868405</td>\n",
       "      <td>0.922329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Statsmodel</td>\n",
       "      <td>0.912436</td>\n",
       "      <td>0.924219</td>\n",
       "      <td>0.802444</td>\n",
       "      <td>0.884835</td>\n",
       "      <td>0.859038</td>\n",
       "      <td>0.863910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.904754</td>\n",
       "      <td>0.888585</td>\n",
       "      <td>0.815838</td>\n",
       "      <td>0.882442</td>\n",
       "      <td>0.850659</td>\n",
       "      <td>0.852599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.872634</td>\n",
       "      <td>0.799545</td>\n",
       "      <td>0.823372</td>\n",
       "      <td>0.860272</td>\n",
       "      <td>0.811283</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.874081</td>\n",
       "      <td>0.840147</td>\n",
       "      <td>0.767286</td>\n",
       "      <td>0.847282</td>\n",
       "      <td>0.802065</td>\n",
       "      <td>0.806145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.849699</td>\n",
       "      <td>0.738383</td>\n",
       "      <td>0.848652</td>\n",
       "      <td>0.849437</td>\n",
       "      <td>0.789687</td>\n",
       "      <td>0.861177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy  Precision    Recall       AUC  \\\n",
       "0                   Random Forest  0.915832   0.896674  0.844132  0.897839   \n",
       "1                         XGBoost  0.915442   0.899820  0.839109  0.896287   \n",
       "2  Logistic Regression Statsmodel  0.912436   0.924219  0.802444  0.884835   \n",
       "3                        AdaBoost  0.904754   0.888585  0.815838  0.882442   \n",
       "4                   Decision Tree  0.872634   0.799545  0.823372  0.860272   \n",
       "5             Logistic Regression  0.874081   0.840147  0.767286  0.847282   \n",
       "6                             KNN  0.849699   0.738383  0.848652  0.849437   \n",
       "\n",
       "   F1(test)  F1(train)  \n",
       "0  0.869610   1.000000  \n",
       "1  0.868405   0.922329  \n",
       "2  0.859038   0.863910  \n",
       "3  0.850659   0.852599  \n",
       "4  0.811283   1.000000  \n",
       "5  0.802065   0.806145  \n",
       "6  0.789687   0.861177  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = pd.DataFrame(scores)\n",
    "eval = eval.rename({0:'Model', 1: 'Accuracy', 2: 'Precision', 3: 'Recall', 4: 'AUC', 5: 'F1(test)', 6: 'F1(train)'}, axis = 1)\n",
    "eval.sort_values(['F1(test)','Recall','F1(train)'], ascending=False).reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on metrics evaluation, Random Forest has the highest F1 and Recall score, thus, we take Random Forest to be used in our model. But, Random Forest has an indication of overfitting based on the test score and the train score, so we have to tuned the hyperparameter of it to make the model more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test Set): 0.91\n",
      "Precision (Test Set): 0.90\n",
      "Recall (Test Set): 0.83\n",
      "AUC (Test Set) : 0.89\n",
      "F1-Score (Test Set): 0.86\n",
      "F1-Score (Train Set): 0.91\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = dict(\n",
    "                       n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1800, num = 23)],\n",
    "                       bootstrap = [True],\n",
    "                       criterion = ['gini','entropy'],\n",
    "                       max_depth = [int(x) for x in np.linspace(1, 110, num = 25)], \n",
    "                       min_samples_split = [5, 10, 15, 20, 25],\n",
    "                       min_samples_leaf = [1, 3, 5, 7, 9],\n",
    "                       max_features = ['auto', 'sqrt', 'log2'], \n",
    "                       n_jobs = [-1],\n",
    "                      )\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_tuned = RandomizedSearchCV(rf, hyperparameters, cv=7, random_state=42)\n",
    "rf_tuned.fit(X_train,y_train)\n",
    "\n",
    "score = eval_classification(rf_tuned,X_train,y_train,X_test,y_test)\n",
    "print(\"Accuracy (Test Set): %.2f\" % score[0])\n",
    "print(\"Precision (Test Set): %.2f\" % score[1])\n",
    "print(\"Recall (Test Set): %.2f\" % score[2])\n",
    "print(\"AUC (Test Set) : %.2f\" % score[3])\n",
    "print(\"F1-Score (Test Set): %.2f\" % score[4])\n",
    "print(\"F1-Score (Train Set): %.2f\" % score[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a46798ea1befe5d3d194ca2d5091003ad94859e0c5c828aac5bdfda75db007ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
